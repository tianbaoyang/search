任务是构建关键字网络
1、数据清洗
2、数据索引
3、数据分析

1、数据清洗：
使用beautifulsoup.jar对html网页解析，获取正文，标题等文本字段
2、数据索引
使用solr/Lucene对文本数据构建索引，以及对索引的查询
Solr是一个开源的搜索服务器，Solr使用Java语言开发，主要基于HTTP和Lucene实现
Solr的特性包括：
 高级的全文搜索功能
 专为高通量的网络流量进行的优化
 基于开放接口（XML !>!1和HTTP）的标准
 综合的HTML管理界面
 可伸缩性－能够有效地复制到另外一个Solr搜索服务器
 使用XML配置达到灵活性和适配性
 可扩展的插件体系

Solr本身是个独立的网络应用程序，需要在Servlet容器中运行来提供服务（使用Jetty/Tomcat等容器）

使用：
1、第一步：搜索引擎规划设计
2、第二步：搜索引擎配置
3、第三步：构建索引并定时更新索引
4、第四步：搜索

数据流图：
索引：
原始数据-》Analyzer分析（切词，停止词过滤，同义词，大小写转换等）-》IndexWriter添加索引-》IndexOutput写入索引-》FSDirectory写入索引
查询：
QueryParse解析用户查询-》BooleanQuery通过boolean关系构建boolean查询-》IndexSearch检索索引-》IndexReader读取索引-》Document满足查询的结果

3、数据分析
1、使用一级关键字作为查询，查找所有符合条件的结果
2、统计研报中推荐个股的数目及数量
3、对所有的结果分词计算IDF值
4、对每一个符合条件的结果分别进行分词，去除停用词，计算所有的TF*IDF值，按关键字的权重进行倒排，取top10
5、统计每个关键字在所有结果的top10中出现的个数，并按个数倒排
6、取上一步的top20作为二级关键字，重复1步骤，获取三级关键字

